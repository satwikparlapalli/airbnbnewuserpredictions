{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS1Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLSfM1iKDXwc"
      },
      "source": [
        "#Importing and Unzipping the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K4eIwiPDiGn"
      },
      "source": [
        "#Importing packages necessary\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGkakBsJ5TtL",
        "outputId": "75d78bde-888d-4d3a-e2ec-9f8f4c2c3aff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK2te2vC5UzH"
      },
      "source": [
        "os.chdir('drive/My Drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759l_YyEO_8T"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "import seaborn as sns\n",
        "from scipy.sparse import hstack, vstack\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import sklearn\n",
        "from sklearn.metrics import make_scorer, ndcg_score\n",
        "import pickle"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQbwHm_I-pWb"
      },
      "source": [
        "'''Extract features like weekday, year, month from date features available'''\n",
        "\n",
        "def extract_weekday(format, datecolumn):\n",
        "  weekdays = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
        "  day_of_week = [weekdays[datetime.strptime(str(x), format).weekday()] for x in datecolumn]\n",
        "  return day_of_week\n",
        "\n",
        "def extract_month(format, datecolumn):\n",
        "  month = [calendar.month_name[datetime.strptime(str(x), format).month] for x in datecolumn]\n",
        "  return month\n",
        "\n",
        "def extract_year(format, datecolumn):\n",
        "  years = [datetime.strptime(str(x), format).year for x in datecolumn]\n",
        "  return years\n",
        "\n",
        "def extract_date(format, datecolumn):\n",
        "  date = [datetime.strptime(str(x), format).day for x in datecolumn]\n",
        "  return date\n",
        "\n",
        "#https://stackoverflow.com/questions/2600775/how-to-get-week-number-in-python\n",
        "def extract_weeknum(format, datecolumn):\n",
        "  weeknum = [datetime.strptime(str(x), format).isocalendar()[1] for x in datecolumn]\n",
        "  return weeknum\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSikDXvSo5uZ"
      },
      "source": [
        "def difference_of_days(dac,tfa):\n",
        "\n",
        "  '''Calculate number of days difference between date first active and date account created feature '''\n",
        "  \n",
        "  #Convert them to date format \n",
        "  dac_dt = datetime.strptime(str(dac), '%Y-%m-%d')\n",
        "  tfa_dt = datetime.strptime(str(tfa), '%Y%m%d%H%M%S')\n",
        "  #Find the difference\n",
        "  no_of_days = dac_dt-tfa_dt\n",
        "  return no_of_days.days\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3IE2ScQD21I"
      },
      "source": [
        "def session_features(feature_name, feature_values,X):\n",
        "\n",
        "  '''Create features in train and test data using dictionary obtained using grouping of sessions data '''\n",
        "\n",
        "  #fetch values from dictionary and create new features in train and test data.\n",
        "  X[feature_name] = [feature_values.get(x,-1) for x in X['id']]\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVLoICiwXLWw"
      },
      "source": [
        "def impute_nulls(feature,feature_type,model,X,cat_cols):\n",
        "\n",
        "  '''Function to impute null values in a feature. \n",
        "  We will take the non-null data to train and encode all categorical columns (as age is only numerical and also it has null values)\n",
        "  and fit the data and predict with data that has null values in train and test data '''\n",
        "    \n",
        "  #Separate null valued rows of given feature from train and test\n",
        "  if feature_type=='numerical':\n",
        "    null_test = X[X[feature]==-1]\n",
        "\n",
        "  if feature_type=='categorical':\n",
        "    null_test = X[X[feature]=='nan']\n",
        "  \n",
        "  if len(null_test)==0:\n",
        "    return X\n",
        "\n",
        "  null_test_enc = model[0].transform(null_test[cat_cols])\n",
        "  imputed_null_test = model[1].predict(null_test_enc)\n",
        "\n",
        "  X.loc[null_test.index, feature] = imputed_null_test\n",
        "\n",
        "  return X"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EVfPtMjcfFM"
      },
      "source": [
        "def preprocess(X):\r\n",
        "  \r\n",
        "  '''Used to preprocess the data.\r\n",
        "  '''\r\n",
        "\r\n",
        "  X['age'] = [np.NaN if ((x>120 and x not in range(1900,2000)) or x<10) else x for x in X['age']]\r\n",
        "  X['day_account_created'] = extract_weekday('%Y-%m-%d', X['date_account_created'])\r\n",
        "  X['month_account_created'] = extract_month('%Y-%m-%d', X['date_account_created'])\r\n",
        "  X['year_account_created'] = extract_year('%Y-%m-%d', X['date_account_created'])\r\n",
        "  X['date__account_created'] = extract_date('%Y-%m-%d', X['date_account_created'])\r\n",
        "  X['week_account_created'] = extract_weeknum('%Y-%m-%d', X['date_account_created'])\r\n",
        "  X['age'] = [int(X.loc[x]['year_account_created'])-X.loc[x]['age'] if X.loc[x]['age'] in range(1900,2000) else X.loc[x]['age'] for x in X.index]\r\n",
        "  X['day_first_active'] = extract_weekday('%Y%m%d%H%M%S', X['timestamp_first_active'])\r\n",
        "  X['month_first_active']=extract_month('%Y%m%d%H%M%S', X['timestamp_first_active'])\r\n",
        "  X['year_first_active']=extract_year('%Y%m%d%H%M%S', X['timestamp_first_active'])\r\n",
        "  X['date_first_active'] = extract_date('%Y%m%d%H%M%S', X['timestamp_first_active'])\r\n",
        "  X['week_first_active'] = extract_weeknum('%Y%m%d%H%M%S', X['timestamp_first_active'])\r\n",
        "  X['days_between_tfa_dac'] = X.apply(lambda x: difference_of_days(x.date_account_created,x.timestamp_first_active), axis=1)\r\n",
        "  # X.drop(['date_first_booking'], axis=1, inplace=True)\r\n",
        "  X['age'] = X['age'].fillna(1)\r\n",
        "  X['gender'] = X['gender'].astype('str')\r\n",
        "  X['age_gender_missing'] = [(2 if (x==1 and y=='-unknown-') else (1 if (x==1 or y=='-unknown-') else 0)) for x,y in zip(X['age'],X['gender'])]\r\n",
        "  X['first_affiliate_tracked'] = X['first_affiliate_tracked'].astype('str')\r\n",
        "  X['signup_flow'] = X['signup_flow'].astype('str')\r\n",
        "\r\n",
        "  sessions = pd.read_csv('sessions.csv')\r\n",
        "  threshold = 8444+(1.5*(8444-229))\r\n",
        "  sessions = sessions[sessions['secs_elapsed']<threshold]\r\n",
        "  sessions['action_type'] = sessions['action_type'].astype('str')\r\n",
        "  sessions['action'] = sessions['action'].astype('str')\r\n",
        "  sessions['action_detail'] = sessions['action_detail'].astype('str')\r\n",
        "  sessions['device_type'] = sessions['device_type'].astype('str')\r\n",
        "\r\n",
        "  mean_elapsed_times = sessions.groupby('user_id')['secs_elapsed'].mean().to_dict()\r\n",
        "  X = session_features('mean_session_time',mean_elapsed_times, X)\r\n",
        "  total_elapsed_times = sessions.groupby('user_id')['secs_elapsed'].sum().to_dict()\r\n",
        "  X = session_features('total_session_time',total_elapsed_times, X)\r\n",
        "  sessions_per_user = sessions.groupby('user_id').count()['secs_elapsed'].to_dict()\r\n",
        "  X = session_features('sessions_per_user',sessions_per_user, X)\r\n",
        "  unique_devices_per_user = sessions.groupby('user_id')['device_type'].nunique()\r\n",
        "  X = session_features('unique_devices_per_user',unique_devices_per_user, X)\r\n",
        "  X['unique_devices_per_user'].replace(-1,X['unique_devices_per_user'].mean(), inplace=True)\r\n",
        "\r\n",
        "  sessions['action_type'] = sessions['action_type'].astype('str')\r\n",
        "  sessions['action'] = sessions['action'].astype('str')\r\n",
        "  sessions['action_detail'] = sessions['action_detail'].astype('str')\r\n",
        "  sessions['device_type'] = sessions['device_type'].astype('str')\r\n",
        "\r\n",
        "  infile = open('Session_dfs.pkl', 'rb')\r\n",
        "  most_occuring_categories, df = pickle.load(infile)\r\n",
        "  infile.close()\r\n",
        "\r\n",
        "  most_occuring_action = most_occuring_categories['action'].to_dict()\r\n",
        "  most_occuring_action_type = most_occuring_categories['action_type'].to_dict()\r\n",
        "  most_occuring_action_detail = most_occuring_categories['action_detail'].to_dict()\r\n",
        "  most_used_device = most_occuring_categories['device_type'].to_dict()\r\n",
        "\r\n",
        "  X['most_occuring_action'] = [most_occuring_action.get(x,'nan') for x in X['id']]\r\n",
        "  X['most_occuring_action_type'] = [most_occuring_action_type.get(x,'nan') for x in X['id']]\r\n",
        "  X['most_occuring_action_detail'] = [most_occuring_action_detail.get(x,'nan') for x in X['id']]\r\n",
        "  X['most_used_device'] = [most_used_device.get(x,'nan') for x in X['id']]\r\n",
        "\r\n",
        "  X['max_elapsed_action_type'] = [df.loc[x][1] if x in df.index else 'nan' for x in X['id']]\r\n",
        "  X['max_elapsed_action'] = [df.loc[x][2] if x in df.index else 'nan' for x in X['id']]\r\n",
        "  X['max_elapsed_time'] = [df.loc[x][3] if x in df.index else -1 for x in X['id']]\r\n",
        "\r\n",
        "  cat_cols = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel',\r\n",
        "        'affiliate_provider', 'first_affiliate_tracked', 'signup_app',\r\n",
        "        'first_device_type', 'first_browser', 'day_account_created', 'month_account_created', 'year_account_created',\r\n",
        "        'date__account_created', 'week_account_created', 'day_first_active',\r\n",
        "        'month_first_active', 'year_first_active', 'date_first_active',\r\n",
        "        'week_first_active','age_gender_missing']\r\n",
        "\r\n",
        "\r\n",
        "  infile = open('ImputingModels.pkl', 'rb')\r\n",
        "  models = pickle.load(infile)\r\n",
        "  infile.close()\r\n",
        "  sessions_numcols = ['mean_session_time','total_session_time','sessions_per_user','max_elapsed_time']\r\n",
        "  sessions_catcols = ['max_elapsed_action_type','max_elapsed_action','most_occuring_action','most_occuring_action_type','most_occuring_action_detail',\r\n",
        "                    'most_used_device']\r\n",
        "  sessions_cols = sessions_catcols+sessions_numcols\r\n",
        "  for i,feature in enumerate(sessions_cols):\r\n",
        "    if feature in sessions_catcols:\r\n",
        "      X=impute_nulls(feature,'categorical',models[i],X,cat_cols)  \r\n",
        "    if feature in sessions_numcols:\r\n",
        "      X=impute_nulls(feature,'numerical',models[i],X,cat_cols)  \r\n",
        "\r\n",
        "  return X"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AumL57R3c-5V"
      },
      "source": [
        "def encode_transform(X):\r\n",
        "  \r\n",
        "  num_cols = ['age','days_between_tfa_dac','mean_session_time','total_session_time','sessions_per_user','max_elapsed_time', 'unique_devices_per_user']\r\n",
        "  cat_cols = ['gender',\r\n",
        "        'signup_method', 'signup_flow', 'language', 'affiliate_channel',\r\n",
        "        'affiliate_provider', 'first_affiliate_tracked', 'signup_app',\r\n",
        "        'first_device_type', 'first_browser',\r\n",
        "        'day_account_created', 'month_account_created', 'year_account_created',\r\n",
        "        'date__account_created', 'week_account_created', 'day_first_active',\r\n",
        "        'month_first_active', 'year_first_active', 'date_first_active',\r\n",
        "        'week_first_active', 'age_gender_missing', 'most_occuring_action',\r\n",
        "        'most_occuring_action_type', 'most_occuring_action_detail',\r\n",
        "        'most_used_device', 'max_elapsed_action_type', 'max_elapsed_action']\r\n",
        "\r\n",
        "  infile = open('Final_Encoder_and_XGBModel.pkl', 'rb')\r\n",
        "  encoder,model,le = pickle.load(infile)\r\n",
        "  infile.close()\r\n",
        "  X_cat = encoder.transform(X[cat_cols])\r\n",
        "  X_num = np.array(X[num_cols])\r\n",
        "  X_transformed = hstack((X_cat, X_num))\r\n",
        "  \r\n",
        "  return X_transformed"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKevecdm1Ajt"
      },
      "source": [
        "def final_fun_1(X):\n",
        "  ''' Function to take raw data as input, do the preprocessing, feed it to model, generate the predictions and return them'''\n",
        "\n",
        "  #Preprocess\n",
        "  X = preprocess(X)\n",
        "  X_transformed = encode_transform(X)\n",
        "\n",
        "  y_pred = model.predict_proba(X_transformed)\n",
        "  predictions = np.array([le.inverse_transform((-1*x).argsort()[:5]) for x in y_pred]).flatten()\n",
        "  test_ids = np.array([[x]*5 for x in X['id']]).flatten()\n",
        "  submission = pd.DataFrame(np.stack((test_ids, predictions), axis=1), columns=['id','country'])\n",
        "\n",
        "  return submission"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "-2THcFta5Hiw",
        "outputId": "b9a9fad3-2a5c-4bac-b114-38321aa36b06"
      },
      "source": [
        "test = pd.read_csv('test_users.csv')\r\n",
        "X = test.iloc[400:403]\r\n",
        "final_fun_1(X)\r\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79vwk4652q</td>\n",
              "      <td>NDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79vwk4652q</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79vwk4652q</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79vwk4652q</td>\n",
              "      <td>FR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79vwk4652q</td>\n",
              "      <td>IT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1lyute4nlz</td>\n",
              "      <td>NDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1lyute4nlz</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1lyute4nlz</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1lyute4nlz</td>\n",
              "      <td>FR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1lyute4nlz</td>\n",
              "      <td>ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>54fjdml43v</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>54fjdml43v</td>\n",
              "      <td>NDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>54fjdml43v</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>54fjdml43v</td>\n",
              "      <td>FR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>54fjdml43v</td>\n",
              "      <td>IT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id country\n",
              "0   79vwk4652q     NDF\n",
              "1   79vwk4652q      US\n",
              "2   79vwk4652q   other\n",
              "3   79vwk4652q      FR\n",
              "4   79vwk4652q      IT\n",
              "5   1lyute4nlz     NDF\n",
              "6   1lyute4nlz      US\n",
              "7   1lyute4nlz   other\n",
              "8   1lyute4nlz      FR\n",
              "9   1lyute4nlz      ES\n",
              "10  54fjdml43v      US\n",
              "11  54fjdml43v     NDF\n",
              "12  54fjdml43v   other\n",
              "13  54fjdml43v      FR\n",
              "14  54fjdml43v      IT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5779Ym7pZyzl"
      },
      "source": [
        "#Function 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drg71GhpZxTM"
      },
      "source": [
        "def final_fun_2(X,y):\r\n",
        "  \r\n",
        "  ''' Function to take raw data along with target variables as input, and calculate and return the metric with predicted and original labels '''\r\n",
        "  \r\n",
        "  X = preprocess(X)\r\n",
        "  X_transformed = encode_transform(X)\r\n",
        "\r\n",
        "  y_pred = model.predict_proba(X_transformed)\r\n",
        "  \r\n",
        "  ohe = OneHotEncoder()\r\n",
        "  ohe.fit(np.array(train[['country_destination']]))\r\n",
        "  y_true=ohe.transform(y.reshape(-1, 1))\r\n",
        "  ndcg_scr = ndcg_score(y_true.toarray(), y_pred)  \r\n",
        "  return ndcg_scr"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9d-0ccZd5Ct",
        "outputId": "a3b821a1-97d0-467a-e80f-90a7400119e4"
      },
      "source": [
        "train = pd.read_csv('train_users_2.csv')\r\n",
        "X=train.drop('country_destination',axis=1).iloc[400:403]\r\n",
        "y=train.iloc[400:403,-1].to_numpy()\r\n",
        "final_fun_2(X,y)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7956176024115139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}